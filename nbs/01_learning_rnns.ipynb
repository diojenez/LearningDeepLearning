{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831f3753-0bd7-43ea-840f-32a22cec5933",
   "metadata": {},
   "source": [
    "# Learning RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a847a",
   "metadata": {},
   "source": [
    "This notebook will mirror the content in Chapter 12 (\"A Language Model from Scatch\") of [*Deep Learning for Coders with fastai & PyTorch*](https://github.com/fastai/fastbook) by Jeremy Howard & Sylvain Gugger, as well as Jeremy's [\"Practical Deep Learning\"](https://course.fast.ai/) course.\n",
    "\n",
    "In an attempt to make sure I understand what is going on under the hood, I'll avoid using the conveniences provided by fastai. That being said, I am not implementing things from scratch and consider anything in Pytorch as fair game.\n",
    "\n",
    "I'll also make it my own by trying to use different datasets and adding anything else that occurs to me that might make the models perform better. We'll see what actually works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfa1fb-2d8d-4402-85b6-949fa36a72ed",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e334783-df67-4728-88d6-db28037697d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    project_path = \"/content/drive/MyDrive/Projects/code/LearningDeepLearning\"\n",
    "    !pip install datasets\n",
    "    !pip install transformers\n",
    "else:\n",
    "    project_path = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f4135-cb37-4f06-ac22-93d8ac4bf6e4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504f41b-63bf-438f-a8d5-e48c56c1c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from psutil import virtual_memory\n",
    "from functools import partial\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3da2d",
   "metadata": {},
   "source": [
    "# Data Prep: TinyStories\n",
    "\n",
    "TinyStories is a dataset developed by Ronen Eldan and Yuanzhi Li and described in their paper [\"TinyStories: How Small Can Language Models Be and Still Speak Coherent English?\"](https://arxiv.org/abs/2305.07759). From the paper, TinyStories is \"a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4.\" The paper goes on to show that they can train \"small\" language models (<10 million parameters) that nevertheless \"produce fluent and consistent stories with several paragraphs that are diverse and have almost perfect grammer, and demonstrate reasoning capabilities.\"\n",
    "\n",
    "We're starting with very rudimentary models with much simpler architecture and even fewer parameters, but let's see how good we can make this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ca12b-475a-4d94-bbc8-eee1a16e11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_limit = 64e4 # limiting amount of data used to speed things up, can relax later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d439c",
   "metadata": {},
   "source": [
    "## Load and inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7a693-4a8e-499e-a87d-5679e2cfc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path(project_path)\n",
    "data_dir = Path(project_dir/'data')\n",
    "data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28f9b9-a3ea-4afe-aff9-41f59ee3deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = \"TinyStoriesV2-GPT4-train.txt\"\n",
    "train_url = \"https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt\"\n",
    "test_fn = \"TinyStoriesV2-GPT4-valid.txt\"\n",
    "test_url = \"https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2aa11-4ade-45e5-8174-c272cd07de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir/train_fn):\n",
    "    os.system(f'wget {train_url} -O {data_path/train_fn} --progress=dot:mega')\n",
    "if not os.path.exists(data_dir/test_fn):\n",
    "    os.system(f'wget {test_url} -O {data_path/test_fn} --progress=dot:mega')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4d075-3376-46ae-b989-ae3e10fbd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: if last doc doesn't end in endoftext then it is omitted\n",
    "def tinystories_generator(file_path, skip_first=False):\n",
    "    current_doc = \"\"\n",
    "    is_first = True\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"<|endoftext|>\"):\n",
    "                if not skip_first or not is_first:\n",
    "                    yield {\"text\": current_doc.strip() + \"<|endoftext|>\"}\n",
    "                is_first = False\n",
    "                current_doc = \"\"\n",
    "            else:\n",
    "                current_doc += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf1b40-255e-45de-99a5-e8b572be075a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7055f64eea149cc90c2c4815e525f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c6c9ca42c04444a449ef5a5f580584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = Dataset.from_generator(partial(tinystories_generator, file_path=data_dir/train_fn))\n",
    "test_ds = Dataset.from_generator(partial(tinystories_generator, file_path=data_dir/test_fn, skip_first=True))\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'test': test_ds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ed443-6dac-4c0f-bbba-906493353b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2717699\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 27629\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d279b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  \\nHe said, “Wow, that is a really amazing vase! Can I buy it?” \\nThe shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\\nSo Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. \\nAnd that's how Ben found an amazing vase in the store!<|endoftext|>\",\n",
       " 'Once upon a time, there was a reliable otter named Ollie. He lived in a river with his family. They all loved to play and swim together.\\nOne day, Ollie\\'s mom said, \"Ollie, hurry and get some fish for dinner!\" Ollie swam fast to catch fish. He saw his friend, the duck. \"Hi, Ollie!\" said the duck. \"Hi, duck!\" said Ollie. \"I need to hurry and catch fish for my family.\"\\nWhile Ollie was catching fish, he found a big shiny stone. He thought, \"This is not a fish, but it is so pretty!\" Ollie took the shiny stone home to show his family. They all looked at the shiny stone and smiled. The shiny stone made everyone happy, and they forgot about the fish for dinner.<|endoftext|>']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0:2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af141777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Once upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.<|endoftext|>',\n",
       "  'Tom and Lily were playing with their toys in the living room. They liked to build towers and bridges with their blocks and cars. Tom was very proud of his tall tower. He wanted to make it even taller, so he reached for more blocks.\\n\"Tom, can I have some blocks too?\" Lily asked. She wanted to make a bridge for her cars.\\n\"No, these are mine. Go find your own,\" Tom said. He did not want to share with his sister. He pulled the blocks closer to him.\\nLily felt sad and angry. She did not think Tom was being nice. She looked at his tower and had an idea. She decided to pull one of the blocks at the bottom of the tower.\\nSuddenly, the tower fell down with a loud crash. All the blocks and cars scattered on the floor. Tom and Lily were shocked. They felt the floor shake and heard a rumble. It was an earthquake!\\n\"Mommy! Daddy!\" they cried. They were scared and ran to their parents, who were in the kitchen.\\n\"Are you okay, kids?\" Mommy asked. She hugged them and checked if they were hurt.\\n\"We\\'re okay, Mommy. But our toys are broken,\" Lily said.\\n\"I\\'m sorry, Lily. But toys are not important. You are important. We are safe and together. That\\'s what matters,\" Mommy said.\\nTom felt sorry for what he did. He realized he was selfish and mean to his sister. He saw how scared she was during the earthquake. He wanted to make her happy.\\n\"Lily, I\\'m sorry I did not share with you. You can have all the blocks you want. I love you, sister,\" Tom said.\\nLily smiled and hugged him. She forgave him and thanked him. She loved him too.\\nThey went back to the living room and cleaned up their toys. They decided to build something together. They made a big house with a garden and a fence. They put their cars and dolls inside. They were happy and proud of their work.\\nMommy and Daddy came to see their house. They praised them and gave them a treat. It was a lemon cake. It was sour, but they liked it. They learned that sharing is caring, and that family is sweet.<|endoftext|>']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de89b33-2546-4541-95bd-57217b5bd7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 12800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 12800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndocs_small = int(token_limit//50)\n",
    "ds_small = DatasetDict({\n",
    "    'train': train_ds.select(range(ndocs_small)),\n",
    "    'test': test_ds.select(range(ndocs_small))\n",
    "})\n",
    "ds_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431865c3",
   "metadata": {},
   "source": [
    "## Tokenize and inspect tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851721a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3636a4fb25b48d6a3acb28ee790afb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46dc9907a9d4039aa226cbdbca79fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654c5881eddf46b2a48eb566f8da2ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fc86c18f8d4b73ab4549136f86b634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5862dd1f6cb54c23bab8e3e87e13de29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pretrained GPT-Neo tokenizer as is used in the TinyStories paper\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec44f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5765ae-42f1-484b-a90b-068305ecc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds_filename = 'tinystories_tokenized_gpt-neo-1.3B'\n",
    "if os.path.exists(data_dir/tds_filename):\n",
    "    tds = load_from_disk(data_dir/tds_filename)\n",
    "else:\n",
    "    tds = ds.map(lambda e: tokenizer(e['text']), batched=True, remove_columns=\"text\")\n",
    "    tds.save_to_disk(data_dir/tds_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632df647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 2717699\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 27629\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc342b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-16d3ab6f-cfb3-4bb1-bfcb-c15637f34385\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>freq</th>\n",
       "      <th>token_str</th>\n",
       "      <th>cdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>41825583</td>\n",
       "      <td>.</td>\n",
       "      <td>0.077245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>23298942</td>\n",
       "      <td>,</td>\n",
       "      <td>0.120274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262</td>\n",
       "      <td>20828658</td>\n",
       "      <td>the</td>\n",
       "      <td>0.158741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290</td>\n",
       "      <td>19476061</td>\n",
       "      <td>and</td>\n",
       "      <td>0.194709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257</td>\n",
       "      <td>15074432</td>\n",
       "      <td>a</td>\n",
       "      <td>0.222549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27989</th>\n",
       "      <td>35172</td>\n",
       "      <td>1</td>\n",
       "      <td>Elves</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27990</th>\n",
       "      <td>16976</td>\n",
       "      <td>1</td>\n",
       "      <td>specialized</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>21942</td>\n",
       "      <td>1</td>\n",
       "      <td>injustice</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>38868</td>\n",
       "      <td>1</td>\n",
       "      <td>adier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27993</th>\n",
       "      <td>45761</td>\n",
       "      <td>1</td>\n",
       "      <td>YING</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27994 rows × 4 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16d3ab6f-cfb3-4bb1-bfcb-c15637f34385')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-16d3ab6f-cfb3-4bb1-bfcb-c15637f34385 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-16d3ab6f-cfb3-4bb1-bfcb-c15637f34385');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-1829d2cc-d584-4714-a9e2-e41b5519cb61\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1829d2cc-d584-4714-a9e2-e41b5519cb61')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const charts = await google.colab.kernel.invokeFunction(\n",
       "          'suggestCharts', [key], {});\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-1829d2cc-d584-4714-a9e2-e41b5519cb61 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       token      freq     token_str       cdf\n",
       "0         13  41825583             .  0.077245\n",
       "1         11  23298942             ,  0.120274\n",
       "2        262  20828658           the  0.158741\n",
       "3        290  19476061           and  0.194709\n",
       "4        257  15074432             a  0.222549\n",
       "...      ...       ...           ...       ...\n",
       "27989  35172         1         Elves  1.000000\n",
       "27990  16976         1   specialized  1.000000\n",
       "27991  21942         1     injustice  1.000000\n",
       "27992  38868         1         adier  1.000000\n",
       "27993  45761         1          YING  1.000000\n",
       "\n",
       "[27994 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_fn = 'tokenfreq_tinystories_tokenized_gpt-neo-1.3B.pkl'\n",
    "if os.path.exists(data_dir/tf_fn):\n",
    "    tf = pd.read_pickle(data_dir/tf_fn)\n",
    "else:\n",
    "    # Initialize a defaultdict to keep track of the frequency of each token\n",
    "    token_freq = defaultdict(int)\n",
    "    # Define a function to update the token frequencies\n",
    "    def update_freqs(batch):\n",
    "        for token_list in batch['input_ids']:\n",
    "            for token_id in token_list:\n",
    "                token_freq[token_id] += 1\n",
    "        return {}\n",
    "    # Apply the function to the dataset\n",
    "    tds['train'].map(update_freqs, batched=True, batch_size=10000)\n",
    "    # Put it in a dataframe and compute cdf\n",
    "    tf = pd.DataFrame(dict(token_freq).items(), columns=('token', 'freq'))\n",
    "    tf['token'] = tf['token'].astype('category')\n",
    "    tf['token_str'] = tf['token'].apply(tokenizer.decode)\n",
    "    tf.sort_values('freq', ascending=False, inplace=True)\n",
    "    tf.reset_index(inplace=True, drop=True)\n",
    "    tf['cdf'] = tf['freq'].cumsum() / tf['freq'].sum()\n",
    "    # Save to disk\n",
    "    tf.to_pickle(data_dir/tf_fn)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6ac14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27994, 50257)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28k tokens in the training set vs. 50k in the tokenizer vocab\n",
    "len(tf), tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d7f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-92944657-b0a8-4cc6-a21e-b0f7a94c3885\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>freq</th>\n",
       "      <th>token_str</th>\n",
       "      <th>cdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>41825583</td>\n",
       "      <td>.</td>\n",
       "      <td>0.077245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>23298942</td>\n",
       "      <td>,</td>\n",
       "      <td>0.120274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262</td>\n",
       "      <td>20828658</td>\n",
       "      <td>the</td>\n",
       "      <td>0.158741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290</td>\n",
       "      <td>19476061</td>\n",
       "      <td>and</td>\n",
       "      <td>0.194709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257</td>\n",
       "      <td>15074432</td>\n",
       "      <td>a</td>\n",
       "      <td>0.222549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>284</td>\n",
       "      <td>14906882</td>\n",
       "      <td>to</td>\n",
       "      <td>0.250080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>373</td>\n",
       "      <td>10594487</td>\n",
       "      <td>was</td>\n",
       "      <td>0.269646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>198</td>\n",
       "      <td>9119907</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0.286489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1119</td>\n",
       "      <td>5226509</td>\n",
       "      <td>They</td>\n",
       "      <td>0.296141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>340</td>\n",
       "      <td>5141200</td>\n",
       "      <td>it</td>\n",
       "      <td>0.305636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92944657-b0a8-4cc6-a21e-b0f7a94c3885')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-92944657-b0a8-4cc6-a21e-b0f7a94c3885 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-92944657-b0a8-4cc6-a21e-b0f7a94c3885');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7423af49-fe05-4010-a23c-af31eaa94c89\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7423af49-fe05-4010-a23c-af31eaa94c89')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const charts = await google.colab.kernel.invokeFunction(\n",
       "          'suggestCharts', [key], {});\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7423af49-fe05-4010-a23c-af31eaa94c89 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  token      freq token_str       cdf\n",
       "0    13  41825583         .  0.077245\n",
       "1    11  23298942         ,  0.120274\n",
       "2   262  20828658       the  0.158741\n",
       "3   290  19476061       and  0.194709\n",
       "4   257  15074432         a  0.222549\n",
       "5   284  14906882        to  0.250080\n",
       "6   373  10594487       was  0.269646\n",
       "7   198   9119907        \\n  0.286489\n",
       "8  1119   5226509      They  0.296141\n",
       "9   340   5141200        it  0.305636"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top ten tokens by frequency, accounting for 30% of all tokens\n",
    "tf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd653bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token           20037\n",
       "freq          1995606\n",
       "token_str        Lily\n",
       "cdf          0.501679\n",
       "Name: 44, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the top 44 account for 50% of all tokens\n",
    "tf.iloc[(0.5 - tf['cdf']).abs().argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e9884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token           1382\n",
       "freq           58844\n",
       "token_str      build\n",
       "cdf          0.89995\n",
       "Name: 793, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the top ~800 account for 90% of all tokens\n",
    "tf.iloc[(0.9 - tf['cdf']).abs().argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a99f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token           10291\n",
       "freq             3663\n",
       "token_str     wanting\n",
       "cdf          0.990001\n",
       "Name: 3709, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the top ~3700 account for 99% of all tokens\n",
    "tf.iloc[(0.99 - tf['cdf']).abs().argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c0cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token             3033\n",
       "freq               119\n",
       "token_str     features\n",
       "cdf           0.999304\n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the top 10k tokens account for 99.93% of tokens, tokens past this appear <120 times in the training set\n",
    "tf.iloc[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee25fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3175, 10009)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3k tokens only appear once, 10k appear 10 or fewer times\n",
    "(tf['freq'] == 1).sum(), (tf['freq'] <= 10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67486d40",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15960101-6487-4b1e-8733-812a6af90498",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "lr = 3e-3\n",
    "epochs = 1\n",
    "seq_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934a3e0-5741-48ad-b176-4824aba3634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7deba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda', 'NVIDIA A100-SXM4-40GB')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    def_device = device_name = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    def_device = 'cuda'\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "else:\n",
    "    def_device = device_name = 'cpu'\n",
    "def_device, device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccab3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.636769792"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_memory().total / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d68e72-0413-4867-81d0-1bf4f9c35a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences_from_doc(doc, seq_len=3):\n",
    "    return [(doc[i:i+seq_len], doc[i+seq_len]) for i in range(0,len(doc)-seq_len-1,seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546604e-9eae-4f12-b31c-ff2bf6506804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences_from_ds(ds, token_limit):\n",
    "    seqs = []\n",
    "    for doc in ds:\n",
    "        i = 0 if len(seqs)==0 else i+1\n",
    "        seqs.extend(get_sequences_from_doc(tensor(doc['input_ids']), seq_len))\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{len(seqs)}/{token_limit} done')\n",
    "        if len(seqs) >= token_limit:\n",
    "            break\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bf479-6a44-4a2f-92f4-49229ebfc3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "62/640000.0 done\n",
      "65885/640000.0 done\n",
      "132398/640000.0 done\n",
      "198478/640000.0 done\n",
      "265368/640000.0 done\n",
      "331051/640000.0 done\n",
      "396882/640000.0 done\n",
      "462737/640000.0 done\n",
      "529767/640000.0 done\n",
      "596213/640000.0 done\n",
      "test\n",
      "69/640000.0 done\n",
      "64681/640000.0 done\n",
      "129571/640000.0 done\n",
      "194245/640000.0 done\n",
      "259498/640000.0 done\n",
      "324271/640000.0 done\n",
      "389586/640000.0 done\n",
      "453914/640000.0 done\n",
      "519785/640000.0 done\n",
      "585284/640000.0 done\n"
     ]
    }
   ],
   "source": [
    "print('train')\n",
    "train_seqs = get_sequences_from_ds(tds['train'], token_limit)\n",
    "print('test')\n",
    "test_seqs = get_sequences_from_ds(tds['test'], token_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de105d13-559d-4e97-b867-3ec3b9751e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_chunks(ds, bs):\n",
    "  m = len(ds)//bs\n",
    "  new_ds = []\n",
    "  for i in range(m): new_ds += ds[i:m*bs:m]\n",
    "  return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b74f68-3cfc-42eb-bcc9-0cac539fba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(group_chunks(train_seqs, bs), batch_size=bs, shuffle=False, drop_last=True)\n",
    "test_dl = DataLoader(group_chunks(train_seqs, bs), batch_size=bs, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ef008-ad16-4a95-8934-a3432067215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976971c3-e17d-4b15-950d-fbb67aa963a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel3(nn.Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "      super().__init__()\n",
    "      self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "      self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "      self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
    "      self.h = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(3):\n",
    "            self.h = self.h + self.i_h(x[:,i])\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "        out = self.h_o(self.h)\n",
    "        self.h = self.h.detach()\n",
    "        return out\n",
    "\n",
    "    def reset(self): self.h = 0\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions based on 3 most recent tokens\n",
    "            logits = self(idx[:,-3:]) # (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1bcf27-3835-4dfe-8b16-d46773abe72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LMModel3(vocab_size, 64).to(def_device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4f98e-f57a-483a-b7b5-d1111a132416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMModel3(\n",
       "  (i_h): Embedding(50257, 64)\n",
       "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (h_o): Linear(in_features=64, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4270d0-6e32-4577-b195-ed45c56ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d7975-7a38-45f1-89d1-a1b153e9b533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[1,   200] loss: 10.526\n",
      "\t[1,   400] loss: 9.558\n",
      "\t[1,   600] loss: 8.828\n",
      "\t[1,   800] loss: 8.240\n",
      "\t[1,  1000] loss: 7.852\n",
      "\t[1,  1200] loss: 7.569\n",
      "\t[1,  1400] loss: 7.329\n",
      "\t[1,  1600] loss: 7.133\n",
      "\t[1,  1800] loss: 6.979\n",
      "\t[1,  2000] loss: 6.843\n",
      "\t[1,  2200] loss: 6.718\n",
      "\t[1,  2400] loss: 6.611\n",
      "\t[1,  2600] loss: 6.512\n",
      "\t[1,  2800] loss: 6.430\n",
      "\t[1,  3000] loss: 6.352\n",
      "\t[1,  3200] loss: 6.283\n",
      "\t[1,  3400] loss: 6.223\n",
      "\t[1,  3600] loss: 6.165\n",
      "\t[1,  3800] loss: 6.109\n",
      "\t[1,  4000] loss: 6.063\n",
      "\t[1,  4200] loss: 6.012\n",
      "\t[1,  4400] loss: 5.971\n",
      "\t[1,  4600] loss: 5.929\n",
      "\t[1,  4800] loss: 5.894\n",
      "\t[1,  5000] loss: 5.856\n",
      "\t[1,  5200] loss: 5.820\n",
      "\t[1,  5400] loss: 5.788\n",
      "\t[1,  5600] loss: 5.757\n",
      "\t[1,  5800] loss: 5.728\n",
      "\t[1,  6000] loss: 5.700\n",
      "\t[1,  6200] loss: 5.671\n",
      "\t[1,  6400] loss: 5.645\n",
      "\t[1,  6600] loss: 5.621\n",
      "\t[1,  6800] loss: 5.599\n",
      "\t[1,  7000] loss: 5.578\n",
      "\t[1,  7200] loss: 5.555\n",
      "\t[1,  7400] loss: 5.535\n",
      "\t[1,  7600] loss: 5.513\n",
      "\t[1,  7800] loss: 5.493\n",
      "\t[1,  8000] loss: 5.474\n",
      "\t[1,  8200] loss: 5.457\n",
      "\t[1,  8400] loss: 5.439\n",
      "\t[1,  8600] loss: 5.423\n",
      "\t[1,  8800] loss: 5.407\n",
      "\t[1,  9000] loss: 5.391\n",
      "\t[1,  9200] loss: 5.375\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward (calc predictions) + backward (calc loss & gradients) +\n",
    "        # optimize (step the weights)\n",
    "        outputs = model(inputs.to(def_device))\n",
    "        loss = criterion(outputs, labels.to(def_device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # tally loss\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "          print(f'\\t[{epoch + 1}, {i + 1:5d}] loss: {running_loss / i:.3f}')\n",
    "    # reset hidden state before validation\n",
    "    model.reset()\n",
    "    # calc validation loss and accuracy\n",
    "    running_valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for valid_i, valid_data in enumerate(test_dl, 0):\n",
    "            inputs, labels = valid_data\n",
    "            outputs = model(inputs.to(def_device))\n",
    "            valid_loss = criterion(outputs, labels.to(def_device))\n",
    "            running_valid_loss += valid_loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(def_device)).sum().item()\n",
    "    # print stats\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] train loss: {running_loss / i:.3f} valid loss: {running_valid_loss / valid_i:.3f} valid i: {valid_i} accuracy: {correct / total:.3f}')\n",
    "    # reset hidden state before next epoch\n",
    "    model.reset()\n",
    "print('Finished Training')\n",
    "end_time = time.time()\n",
    "print(f'{end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987893c-ffd2-4d92-a2a0-04943c7d1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some generation\n",
    "prompt = tensor(tds['train'][0]['input_ids'][:3])\n",
    "gen_txt = model.generate(idx = prompt.view(1,3).to(def_device), max_new_tokens=20)[0].tolist()\n",
    "print(tokenizer.decode(gen_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21005f9-31ab-463f-8e2d-86db39b3d85f",
   "metadata": {},
   "source": [
    "**Log results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84c460-f974-48d3-9a56-d417bbb4db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path(project_dir/'logs')\n",
    "log_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6324302-2f7c-42a8-8d25-b1f904c9d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = log_dir/'log.pkl'\n",
    "if os.path.exists(log_path):\n",
    "    log = pd.read_pickle(log_path)\n",
    "else:\n",
    "    log = pd.DataFrame(columns=['model', 'params', 'device_name', 'vocab_size', 'train_tokens', 'test_tokens', 'batch_size',\n",
    "                                'epochs', 'train_time', 'train_loss', 'test_loss', 'accuracy', 'sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d2140-fbef-47ed-ac9d-925dedc9af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = \\\n",
    "pd.concat([log,\n",
    "           pd.DataFrame({'model': model.__class__.__name__, 'params': get_params(model),'device_name': device_name,\n",
    "                         'vocab_size': tokenizer.vocab_size, 'train_tokens': len(train_dl)*bs, 'test_tokens': len(test_dl)*bs,\n",
    "                         'batch_size': bs, 'epochs':epochs, 'train_time': end_time-start_time,\n",
    "                         'train_loss': running_loss / i, 'test_loss': running_valid_loss / valid_i, 'accuracy': correct / total,\n",
    "                         'sample': tokenizer.decode(gen_txt)}, index=[len(log)])\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e244a3-fa6d-4aac-90ed-3c9697134b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>device_name</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>train_tokens</th>\n",
       "      <th>test_tokens</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LMModel3</td>\n",
       "      <td>6487313</td>\n",
       "      <td>mps</td>\n",
       "      <td>50257</td>\n",
       "      <td>640000</td>\n",
       "      <td>640000</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>296.992819</td>\n",
       "      <td>5.323405</td>\n",
       "      <td>4.635509</td>\n",
       "      <td>0.230780</td>\n",
       "      <td>Once upon a time again, wings into should. Whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LMModel3</td>\n",
       "      <td>6487313</td>\n",
       "      <td>Tesla T4</td>\n",
       "      <td>50257</td>\n",
       "      <td>640000</td>\n",
       "      <td>640000</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>53.839692</td>\n",
       "      <td>5.314124</td>\n",
       "      <td>4.639222</td>\n",
       "      <td>0.232855</td>\n",
       "      <td>Once upon a timeubuntu Buddy the best, Amy set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LMModel3</td>\n",
       "      <td>6487313</td>\n",
       "      <td>Tesla V100-SXM2-16GB</td>\n",
       "      <td>50257</td>\n",
       "      <td>640000</td>\n",
       "      <td>640000</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>39.803033</td>\n",
       "      <td>5.283554</td>\n",
       "      <td>4.619744</td>\n",
       "      <td>0.228327</td>\n",
       "      <td>Once upon a time house Nato the small by and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LMModel3</td>\n",
       "      <td>6487313</td>\n",
       "      <td>NVIDIA A100-SXM4-40GB</td>\n",
       "      <td>50257</td>\n",
       "      <td>640000</td>\n",
       "      <td>640000</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>33.560122</td>\n",
       "      <td>5.319119</td>\n",
       "      <td>4.627001</td>\n",
       "      <td>0.233545</td>\n",
       "      <td>Once upon a time wheni when Mia somethingMobil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model   params            device_name vocab_size train_tokens  \\\n",
       "0  LMModel3  6487313                    mps      50257       640000   \n",
       "1  LMModel3  6487313               Tesla T4      50257       640000   \n",
       "2  LMModel3  6487313   Tesla V100-SXM2-16GB      50257       640000   \n",
       "3  LMModel3  6487313  NVIDIA A100-SXM4-40GB      50257       640000   \n",
       "\n",
       "  test_tokens batch_size epochs  train_time  train_loss  test_loss  accuracy  \\\n",
       "0      640000         64      1  296.992819    5.323405   4.635509  0.230780   \n",
       "1      640000         64      1   53.839692    5.314124   4.639222  0.232855   \n",
       "2      640000         64      1   39.803033    5.283554   4.619744  0.228327   \n",
       "3      640000         64      1   33.560122    5.319119   4.627001  0.233545   \n",
       "\n",
       "                                              sample  \n",
       "0  Once upon a time again, wings into should. Whe...  \n",
       "1  Once upon a timeubuntu Buddy the best, Amy set...  \n",
       "2  Once upon a time house Nato the small by and s...  \n",
       "3  Once upon a time wheni when Mia somethingMobil...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb2fc3-99a8-484b-b5e3-a6fe9442ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(log, log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1a0d5-d3d3-446e-a3b9-613253772968",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "First, very simple model (LMModel3) training for one epoch with only 64k tokens took 5 minutes on my Macbook and less than a minute on Colab with a real GPU. The A100 was only twice as fast at the T4, which just suggests we are no where near to the point where we need the power of the A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa426cc4-706f-4c47-b834-5f21b219be72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
